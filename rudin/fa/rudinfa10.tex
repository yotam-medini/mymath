%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapterTypeout{Banach Algebras}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Exercises} % pages 271-274

Throughout this set of exercises,
$A$ denotes a Banach algebra and \(x, y, \ldots\) denote
elements of $A$, unless the contrary is stated.

%%%%%%%%%%%%%%%%%
\begin{enumerate}
%%%%%%%%%%%%%%%%%

%%%%%%% 1
\begin{excopy}
Use the identity \((xy)^n = x(yx)^{n-1}y\) to prove that \(xy\) and \(yx\)
always have the same spectral radius.
\end{excopy}

\begin{align*}
 \rho(xy) &= \lim_{n\to\infty} \|(xy)^n\|^{1/n} = \lim_{n\to\infty}\|x(yx)^{n-1}y\|^{1/n} \\
  &\leq \lim_{n\to\infty} \left(\|x\|\cdot \|(yx)^{n-1}\|\cdot \|y\|\right)^{1/n} \\
  &= \left(\lim_{n\to\infty} \|x\|^{1/n}\right)
     \cdot
     \left(\lim_{n\to\infty} \|(yx)^{n-1}\|^{1/n}\right)
     \cdot
     \left(\lim_{n\to\infty} \|y\|^{1/n}\right) \\
  &= 1 \cdot \left(\lim_{n\to\infty} \|(yx)^{n-1}\|^{1/n}\right) \cdot 1
   = \lim_{n\to\infty} \|(yx)^{n-1}\|^{1/n} \\
  &= \lim_{n\to\infty} \left(\|(yx)^{n-1}\|^{1/(n-1)}\right)^{n/n-1} \\
  &= \lim_{n\to\infty} \left(\rho(yx)\right)^{n/(n-1)} = \rho(yx)
\end{align*}

%%%%%%% 2
\begin{excopy}
\begin{itemize}
  \itemch{a}
    If $x$ and \(xy\) are invertible in $A$, prove that $y$ is invertible.
  \itemch{b}
    If \(xy\) and \(yx\) are invertible in $A$,
    prove that $x$ and $y$ are invertible. (The
    commutative case of this was tacitly used in the proofs of Theorems~10.13
    and 10.28.)
  \itemch{c}
    Show that it is possible to have \(xy = e\) but \(yx \neq e\).
    For example, consider the
    right and left shifts \(S_R\), and \(S_L\),
    defined on some Banach space of functions $f$
    on the nonnegative integers by
    \begin{align*}
     (S_R f)(n) &= f(n - 1) \qquad \textnormal{if}\quad n \geq 1,\\
     (S_R f)(0) &= 0, \\
     (S_L f)(0) &= f(n + 1) \qquad \textnormal{for all}\quad n \geq 0.
    \end{align*}
  \itemch{d}
    If \(xy = e\) and \(yx = z \neq e\),
    show that $z$ is a nontrivial idempotent. (This
    means that \(z^2 = z\), \(z \neq 0\), \(z \neq e\).)
\end{itemize}
\end{excopy}

\begin{itemize}
  \itemch{a}
    Let \(z = (xy)^{-1} x\). Now using associativity
    \begin{equation*}
      zy = ((xy)^{-1} x)y = (xy)^{-1}(xy) = e
    \end{equation*}
    and 
    \begin{align*}
      yz &= y((xy)^{-1} x) = (x^{-1} x)(y((xy)^{-1} x) = x^{-1}(xy)(xy)^{-1} x \\
         &= x^{-1}((xy)(xy)^{-1})x = x^{-1}ex = e.
    \end{align*}
    Hence \(z = y^{-1}\).
  \itemch{b}
    We have two sides ``inverses'':
    \(((yx)^{-1}y)\cdot x = e\)
    and
    \(x\cdot(y(xy)^{-1}) = e\).
    Put \(a = (yx)^{-1}y\) and \(b = y(xy)^{-1}\)
    so \(ax = xb = e\). Now
    \(a = a(xb) = (ax)b = b\)
    Thus \(x^{-1} = a = b\).
    By symmetry $y$ is invertible as well.
  \itemch{c}
    Indeed \(S_L\cdot S_R = e\) but \(S_R\cdot S_L \neq e\).
  \itemch{d}
    Showing idempotent: \(z^2 = (yx)(yx) = y(xy)x = yex = yx = z\).
    If by negation \(z=0\) then \(e = xy = x(yx)y = 0\) contradiction.
\end{itemize}

%%%%%%% 3
\begin{excopy}
Prove that every finite-dimensional $A$ is isomorphic to an algebra of matrices.
\emph{Hint}:
The proof of Theorem~10.2 shows that every $A$ is isomorphic to
a sub-algebra of \(\scrB(A)\).
Conclude that \(xy = e\) implies \(yx = e\) if \(\dim A < \infty\).
\end{excopy}

Let \seq{a}{n} be a base for $A$.
Using the unique linear combination of the base,
let \(\beta: A \to \C^n\) defined such that
\begin{equation*}
 \forall x\in A, \qquad
 x = \sum\nolimits_{j=1}^n \left(\beta(x)\right)_j a_j.
\end{equation*}
Clearly \(\beta\) is a linear operator.
Any operator in \(\scrB(A)\) is determined by its action on the base.
\iffalse
For any \(j,k\in\N_n\) let \(b_{j,k}\) be defined such that
\begin{equation*}
a_j\cdot a_k = \sum\nolimits_{k=1}^n b_{j,k} a_k.
\end{equation*}
\fi
Let \(\rho,x \in A\), and \(\rho\cdot x = y\).
Let see how \(\beta(x)\) is \(\rho\)-mapped to \(\beta(y)\).
\begin{equation*}
\rho\cdot x =
  \left(\sum\nolimits_{j=1}^n \left(\beta(\rho)\right)_j a_j\right)
  \cdot
  \left(\sum\nolimits_{j=1}^n \left(\beta(x)\right)_j a_j\right)
  =
  \left(\sum\nolimits_{j=1}^n \left(\beta(y)\right)_j a_j\right)
\end{equation*}
Let \(r_{j,k} = \left(\beta(\rho(a_j)\right)_k\) where \(j,k\in\N_n\).
Let \(R_\rho = (r_{j,k})_{j,k=1}^n\) be a \(n\times n\) matrix.
we need to show the following equality in \(\C^n\)
\begin{equation*}
R_\rho\cdot \beta(x) = \beta(y).
\end{equation*}
By linearity, it is sufficient to show the equality for \(x=a_j\).
For each \(k\in\N_n\)
\begin{equation*}
\left(R_\rho\cdot \beta(a_j) \right)_k = r_{j,k}.
\end{equation*}
Thus we have an isomorphism \(A \leftrightarrow \C^{n^2}\).
From the theory of matrices, we know that a matrix $M$ is
invertible iff \(\det(M)\neq 0\).

Now say the isomorphism maps \(x\to M_1\) and \(y\to M_2\).
If \(M_1\times M_2 = I_n\) as \(n\times n\) matrices,
then \(\det(M_1) \neq 0 \neq \det(M_2)\).
Thus both matrices are invertible, the inverse is unique
and so  \(M_2\times M_1 = I_n\) as well.
So if \(xy=e\) then \(yx=e\).

%%%%%%% 4
\begin{excopy}
\begin{itemize}
\itemch{a}
Prove that \(e - yx\) is invertible in $A$
if \(e - xy\) is invertible. \emph{Suggestion:} Put
\(z =(e-xy)^{-1}\), write $z$ as a geometric series
(assume \(\|x\| < 1\), \(\|y\| < 1\)), and
use the identity stated in Exercise~1
to obtain a finite formula for \((e - yx)^{-1}\)
in terms of $x$, $y$, $z$. Then show that this formula works without any
restrictions on \(\|x\|\) or \(\|y\|\).
\itemch{b}
If \(\lambda \in \C\) \(\lambda \neq 0\),
  and \(\lambda \in \sigma(xy)\), prove that \(\lambda \in \sigma(yx)\).
  Thus \(\sigma(xy) \cup \{0\} = \sigma(yx) \cup \{0\}\).
  Show, however, that \(\sigma(xy)\) is not always equal to \(\sigma(yx)\).
\end{itemize}
\end{excopy}

\begin{itemize}
\itemch{a}
As geometric series
\begin{equation*}
z = \sum\nolimits_{k=0}^\infty (xy)^k
\end{equation*}
Now
\begin{equation*}
yzx
= \sum\nolimits_{k=0}^\infty y(xy)^kx
= \sum\nolimits_{k=1}^\infty (yx)^k
\end{equation*}
so as a conjecture
\begin{equation} \label{eq:conj:inv:emyx}
e + yzx = \sum\nolimits_{k=0}^\infty (yx)^k = (e - yx)^{-1}.
\end{equation}
Checking from left
\begin{align*}
(e + yzx)\cdot(e - yx)
 &= e - yx + yzx - yzxyx
  = e + y(z - zxy - e)x \\
 &= e + y(z(e - xy) - e)x 
  = e + y\cdot 0\cdot x = e
\end{align*}
and checking from right
\begin{align*}
(e - yx)\cdot(e + yzx)
 &= e + yzx - yx - yxyzx = e + y(z - xyz - e)x \\
 &= e + y((e - xy)z - e)x
    = e + e\cdot 0\cdot x = e
\end{align*}
So the \eqref{eq:conj:inv:emyx} conjecture holds.
\itemch{b}
Let \(\mu = \lambda^{-1}\).
Note that \(\mu (xy) = (\mu x)y = x(\mu y)\)
and \(\mu (yx) = (\mu y)x = y(\mu x)\).
By assumption \(xy -\lambda e\) is not invertible
and so \(\mu xy - e\) is not invertible.
By \ich{a} \(\mu yx - e\) is not invertible
and so \(yx - \lambda e\) is not invertible. Thus \(\lambda \in \sigma(yx)\).

Using exercise~2.\ich{c},
We have \(S_L\cdot S_R = e\) and \(S_R\cdot S_L \neq e\)
and for any \(x\in\ell^p\) we have \(((S_R\cdot S_L)(x))(0) = 0\)
which shows that \(S_R\cdot S_L\) is not invertible.
Thus \(0 \in \sigma(S_R\cdot S_L) \setminus  \sigma(S_L\cdot S_R) \),
and \(\sigma(S_R\cdot S_L) \neq  \sigma(S_L\cdot S_R)\).
\end{itemize}

%%%%%%% 5
\begin{excopy}
Let \(A_0\) and \(A_1\),
be the algebras of all complex 2-by-2 matrices of the form

\begin{equation*}
\left(
  \begin{array}{ll}
   \alpha & 0 \\
   0 & \beta
  \end{array}
\right),
\qquad
\left(
  \begin{array}{ll}
   \alpha & \beta \\
   0 & \alpha
  \end{array}
\right).
\end{equation*}
Prove that every two-dimensional complex algebra $A$ with unit $e$ is isomorphic
to one of these
  and that \(A_0\) is not isomorphic to \(A_1\).
    \emph{Hint:} Show that $A$ has a
basis \(\{e, a\}\) in which \(a^2 = \lambda e\) for some \(\lambda \in \C\).
  Distinguish between the cases
  \(\lambda=0\), \(\lambda \neq 0\).
  Show that there exists a three-dimensional noncommutative
Banach algebra.
\end{excopy}

We have \(a\in A_0\) such that \(\{I, a\}\) is a base and
\(a^2 = \lambda e\) with \(\lambda \neq 0\).
for example: \(a = \left(
\begin{smallmatrix}
1 & 0 \\
0 & -1
\end{smallmatrix}
\right)\).
But by negation if we have such an \(a\in A_1\) we would have
\begin{equation*}
a^2 =
\left(
\begin{array}{ll}
\alpha & \beta \\
0 & \alpha \\
\end{array}\right)^2 =
\left(
\begin{array}{ll}
\alpha^2 & 2\alpha\beta \\
0 & \alpha^2 \\
\end{array}\right) = \lambda I
\end{equation*}
But then \(\alpha=0\) or \(\beta=0\) and in both cases \(\{I, a\}\)
would not span $A$, contradicting the base assumption.
This \(A_0\) and \(A_1\) are not isomorphic.

Let \(\{e, b\}\) be an arbitrary base for 2-dimensional $A$.
Look at a linear combination \(b^2 = \alpha e + \beta b\)
where \(\alpha,\beta \in \C\).
Consider
\((b + ze)^2 = (\alpha + z^2) e + (\beta + 2z)b\),
so we pick \(z = -\beta/2\), \(a = b + ze\) and \(\lambda = \alpha + z^2\)
so we have (as the hint) a base \(\{e, a\}\) and \(a^2 = \lambda e\).
If \(\lambda \neq 0\) we have isomorphism with \(A_0\)
\begin{equation*}
  \alpha e + \beta a \to
  \left(
  \begin{array}{ll}
  \alpha + \beta & 0 \\
  0 & \alpha - \beta
  \end{array}
  \right).
\end{equation*}
If \(\lambda = 0\) we have isomorphism with \(A_1\)
\begin{equation*}
  \alpha e + \beta a \to
  \left(
  \begin{array}{ll}
  \alpha & \beta \\
  0 & \alpha
  \end{array}
  \right).
\end{equation*}

Look at the $3$-dimensional algebra of the \(2\times 2\)
complex matrices of the form
\(\left(
\begin{smallmatrix}
\alpha & \beta \\
0 & \gamma
\end{smallmatrix}
\right)\).
Now
\begin{equation*}
\left(
  \begin{array}{ll}
   \alpha_1 & \beta_1 \\
   0 & \gamma_1
  \end{array}
\right)
\cdot
\left(
  \begin{array}{ll}
   \alpha_2 & \beta_2 \\
   0 & \gamma_2
  \end{array}
\right)
=
\left(
  \begin{array}{ll}
   \alpha_1\alpha_2 & \alpha_1\beta_2 + \beta_1\gamma_2 \\
   0 & \gamma_1\gamma_2
  \end{array}
\right).
\end{equation*}
and
\begin{equation*}
\left(
  \begin{array}{ll}
   \alpha_2 & \beta_2 \\
   0 & \gamma_2
  \end{array}
\right)
\cdot
\left(
  \begin{array}{ll}
   \alpha_1 & \beta_1 \\
   0 & \gamma_1
  \end{array}
\right)
=
\left(
  \begin{array}{ll}
   \alpha_2\alpha_1 & \alpha_2\beta_1 + \beta_2\gamma_1 \\
   0 & \gamma_2\gamma_1
  \end{array}
\right).
\end{equation*}
So if we pick \(\alpha_1 = \alpha_2 = \beta_1 = \gamma_2 = 0\)
and \(\beta_2 = \gamma_1 = 1\) we see that this algebra is noncommutative.

%%%%%%% 6
\begin{excopy}
Let $A$ be the algebra of all complex functions $f$ on
\(\{1, 2, 3, \ldots\}\) which are $0$
except at finitely many points, with pointwise addition and multiplication and
norm
\begin{equation*}
 \|f\| = \sum\nolimits_{k=1}^\infty k^{-2}|f(k)|.
\end{equation*}
Show that multiplication is left-continuous
  (hence also right-continuous, since $A$
is commutative) but not jointly continuous. (Adjunction of a unit element, as
suggested in Section~10.1, would make no difference.)
  Show, in fact, that there is
a~sequence \(\{f_n\}\) in $A$ so that \(\|f_n\| \to 0\)
  but \(\|f_n^2\| \to \infty\), as \(n \to \infty\).
\end{excopy}

The continuity of single side is trivial
since in the limit of
\(\lim_{n\to\infty} f_n\cdot g\)
or
\(\lim_{n\to\infty} g\cdot f_n\)
the g function is constant
and the formal infinite sum is actually a finite sum,
since $g$ is $0$ except or finite set of points.
The finite sum of limits is clearly the limit of the sums.

Let \(h(n) = (1/\left(\log(n))^{1/4}\right)\)
Clearly
Define \(f_n : \N \to \C\) by
\begin{equation*}
f_n(k) = \left\{
\begin{array}{ll}
h(n)\cdot k^{2/3} & \quad \textnormal{if}\; n > 1 \land 0 < k \leq n \\
0 & \quad \textnormal{if}\; n = 1 \lor k > n 
\end{array}\right.
\end{equation*}
\begin{equation*}
h(n)\cdot\|f_n\|
  = \sum\nolimits_{k=2}^n k^{-2+2/3}\
  \leq \sum\nolimits_{k=2}^\infty k^{-4/3}
  \leq \int\nolimits_0^\infty x^{-4/3}\,dx
  = -1/(-4/3 + 1) = 3.
\end{equation*}
Thus \(\lim_{n\to\infty} \|f_n\| = 0\).
But
\begin{align*}
\lim_{n\to\infty} \|f_n^2\|
 &= \lim_{n\to\infty} \sum\nolimits_{k=1}^n (h(n))^2\cdot k^{-2+4/3}
   = \lim_{n\to\infty} h(n)^2\cdot \sum\nolimits_{k=1}^n k^{-2/3} \\
 & \geq \lim_{n\to\infty} \left(\log(n)\right)^{-1/2}
     \cdot  \sum\nolimits_{k=1}^\infty k^{-1}
   \geq \lim_{n\to\infty} \left(\log(n)\right)^{-1/2} \log(n) \\
 &= \lim_{n\to\infty} \left(\log(n)\right)^{1/2} = \infty.
\end{align*}

%%%%%%% 7
\begin{excopy}
Let \(C^2 = C^2([0, 1))\) be the space of all complex functions
  on \([0, 1]\) whose
second derivative is continuous. Choose \(a > 0\), \(b > 0\), and define
\begin{equation*}
\|f\| = \|f\|_\infty + a\|f'\|_\infty +  b\|f''\|_\infty +
\end{equation*}
Show that this makes \(C^2\) into a Banach space,
  for every choice of $a$, $b$, but that
the Banach algebra axioms hold
 if and only if \(2b \leq a^2\).
 (For necessity, consider $x$ and \(x^2\).)
\end{excopy}

Assume the defined \(\|\|\) is an algebra norm.
Let \(f(x)=x\). So \((f^2)'(x) = 2x\) and
\hbox{\((f^2)''(x) = 2\)}.
We need \(\|f\cdot f\| \leq \|f\|\cdot\|f\|\) to hold.
\begin{align*}
1 + a\cdot 2 + b\cdot 2 &\leq (1 + a\cdot 1 + b\cdot 0)^2 \\
\Rightarrow 2a + 2b + 1 &\leq (a + 1)^2 \\
\Rightarrow 2b &\leq a^2.
\end{align*}

Conversely, assume \(2b \leq a^2\).
Pick arbitrary \(f,g\in C^2\).
\begin{equation*}
\newcommand{\IN}[1]{\|{#1}\|_\infty}
\arraycolsep=1.4pt
\def\arraystretch{1.6}
\begin{array}{lcl}
\|fg\|
 &=& \IN{fg} + a\IN{f'g + fg'} +  b\IN{f''g + 2f'g' + fg''} \\
 &\leq&  \IN{f}\cdot\IN{g} +
         a\left(\IN{f'}\cdot\IN{g} + \IN{f}\cdot\IN{g'}\right) + \\
 &&      b\left(\IN{f''}\cdot\IN{g} + \IN{f}\cdot\IN{g''}\right) +
         2b\IN{f'}\cdot\IN{g'} \\
 &\leq& \IN{f}\cdot\IN{g} +
         a\left(\IN{f'}\cdot\IN{g} + \IN{f}\cdot\IN{g'}\right) + \\
 &&      b\left(\IN{f''}\cdot\IN{g} + \IN{f}\cdot\IN{g''}\right) +
         a^2\IN{f'}\cdot\IN{g'} \\
 &\leq& \IN{f}\cdot\IN{g} +
        a\left(\IN{f}\cdot\IN{g'} + \IN{f'}\cdot\IN{g}\right) + \\
 &&     b\left(\IN{f}\cdot\IN{g''} + \IN{f''}\cdot\IN{g}\right) +
        a^2\IN{f''}\IN{g''} +
        ab\IN{f'}\IN{g''} \\
 &=& (\IN{f} + a\IN{f'} +  b\IN{f''})
     \cdot
     (\IN{g} + a\IN{g'} +  b\IN{g''}) \\
 &=& \IN{f}\cdot\IN{g}.
\end{array}
\end{equation*}
So the inequality of norm required for algebra holds.

%%%%%%% 8
\begin{excopy}
What happens if the process of adjoining a unit (described in Section~10.1) is
applied to an algebra $A$ which already has a unit? Clearly,
  the result cannot be
an algebra $A$, with two units, Explain.
\end{excopy}

Following the Section~10.1 notation.
If the original algebra $A$ has a unit \(e_A\)
then it is mapped to \((e_A,0) \in A_1\)
which is \emph{not} a unit in \(A_1\).
For example:
\begin{equation*}
  (e_A,0)\cdot(0, 1) = (e_A,0) \neq (0, 1).
\end{equation*}

%%%%%%% 9
\begin{excopy}
Suppose that \(\Omega\) is open in \(\C\)
and that \(f: \Omega \to A\)
and \(\phi: \Omega \to \C\) are holomorphic.
Prove that \(\phi : \Omega \to A\) is holomorphic.
[This was used in the proof of Theorem~10.13,
  with \(\phi(\lambda) = \lambda^n\).]
\end{excopy}

\unfinished

%%%%%%% nn
\begin{excopy}
\end{excopy}

\unfinished

%%%%%%%%%%%%%%%
\end{enumerate}
%%%%%%%%%%%%%%%
